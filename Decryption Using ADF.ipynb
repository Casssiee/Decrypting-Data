{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decrypting Encrypted Data (From BluePrism)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install pyaes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import libraries\n",
    "import os\n",
    "import pandas as pd\n",
    "from pandas import DataFrame\n",
    "import hashlib\n",
    "import datetime\n",
    "import numpy as np\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Define input parameters \n",
    "container_name, folder_name_encrypted, filename_encrypted = [dbutils.widgets.get(i) for i in ['container_name', 'folder_name_encrypted', 'filename_encrypted']]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define output parameters\n",
    "container_name, folder_name_decrypted, filename_decrypted = [dbutils.widgets.get(i) for i in ['container_name', 'folder_name_decrypted', 'filename_decrypted']]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set the Blob storage\n",
    "storage_account = 'aihubdatalake'\n",
    "\n",
    "account_key = dbutils.secrets.get(scope = 'aihubdatalake-key', key = 'aihubdatalake-key')\n",
    "spark.conf.set(\n",
    "  f'fs.azure.account.key.{storage_account}.blob.core.windows.net',\n",
    "  f'{account_key}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define functions to get files and store files\n",
    "import os\n",
    "\n",
    "def wasbs_str(container_name, folder):\n",
    "  return f'wasbs://{container_name}@{storage_account}.blob.core.windows.net/{folder}/'\n",
    "\n",
    "def wasbs_file_str(container, folder, file):\n",
    "  return f'wasbs://{container_name}@{storage_account}.blob.core.windows.net/{folder}/{file}'\n",
    "\n",
    "def wasbs_folder_str(container, folder):\n",
    "  return f'wasbs://{container}@{storage_account}.blob.core.windows.net/{folder}/'\n",
    "\n",
    "def first_object(container, ind, folder):\n",
    "  return dbutils.fs.ls(wasbs_str(container, folder))[ind][0]\n",
    "\n",
    "def save_to_storage(df, container_name, filename, folder):\n",
    "    df.to_parquet(f\"/dbfs/FileStore/tables/{filename}\")\n",
    "    return (dbutils.fs.cp(f'/FileStore/tables/{filename}', f'{wasbs_folder_str(container_name, folder)}{filename}'))\n",
    "\n",
    "spark.conf.set(\n",
    "  f'fs.azure.account.key.{storage_account}.blob.core.windows.net',\n",
    "  f'{account_key}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get the encrypted files from the folder\n",
    "storage_path = wasbs_file_str(container_name, folder_name_encrypted, filename_encrypted) # wasbs_file_str(container_name, folder_name)\n",
    "dbutils.fs.cp(storage_path, '.')\n",
    "local_path=f'/dbfs/{os.path.basename(storage_path)}'\n",
    "df_filename_encrypted = pd.read_parquet(local_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set the BP key from key vault \n",
    "storage_account = 'aihubdatalake'\n",
    "\n",
    "encryption_key = dbutils.secrets.get(scope = 'BP-encryption-key', key = 'BP-encryption-key')\n",
    "spark.conf.set(\n",
    "  f'fs.azure.account.key.{storage_account}.blob.core.windows.net',\n",
    "  f'{account_key}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#For P181 Leave Booking we need to get [uniqueid], [status], [loaded], [finished], [data], [attempt], [tag]\n",
    "#For P181 Travel Dairy Details and P181 Travel Diaries Leave Audit we need to get [uniqueid], [status], [loaded], [finished], [data]\n",
    "#For P175, P103, P202, P76 we need to get [uniqueid], [data], [loaded]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Decrypting data\n",
    "import pyaes, base64\n",
    "import pandas as pd\n",
    "\n",
    "# Decode key from base64\n",
    "BPkey = encryption_key\n",
    "BPkey = base64.b64decode(BPkey)\n",
    "\n",
    "# Load data from CSV file\n",
    "df = df_filename_encrypted\n",
    "\n",
    "# Create an empty list to store columns and decrypted data \n",
    "decrypted_data = []\n",
    "\n",
    "# Loop through each row in the dataframe\n",
    "for index, row in df.iterrows():\n",
    "\n",
    "    # Extract IV and columns from the 'EncryptedData' column\n",
    "    iv, queuedata = row['data'].split(':')\n",
    "    itemid = row['itemid']\n",
    "    queueid = row['queueid']\n",
    "    queuename = row['queuename']\n",
    "    keyfield = row['keyfield']\n",
    "    keyvalue = row['keyvalue']\n",
    "    status = row['status']\n",
    "    attempt = row['attempt']\n",
    "    tag = row['tag']\n",
    "    loaded = row['loaded']\n",
    "    completed = row['completed']\n",
    "    exception = row['exception']\n",
    "    exceptionreason = row['exceptionreason']\n",
    "    deferred = row['deferred']\n",
    "    finished = row['finished']\n",
    "    lastupdated = row['lastupdated']\n",
    "    worktime = row['worktime']\n",
    "    sessionid = row['sessionid']\n",
    "    priority = row['priority']\n",
    "    prevworktime = row['prevworktime']\n",
    "    attemptworktime = row['attemptworktime']\n",
    "    exceptionreasonvarchar = row['exceptionreasonvarchar']\n",
    "    exceptionreasontag = row['exceptionreasontag']\n",
    "    uniqueid = row['uniqueid']\n",
    "    ident = ['ident']\n",
    "    \n",
    "    # Decode from base64\n",
    "    iv = base64.b64decode(iv) \n",
    "    queuedata = base64.b64decode(queuedata)\n",
    "\n",
    "    # Decrypt the ciphertext with the given key:\n",
    "    aes = pyaes.Decrypter(pyaes.AESModeOfOperationCBC(BPkey, iv=iv))\n",
    "    decrypted = aes.feed(queuedata)\n",
    "    decrypted += aes.feed()\n",
    "    decrypted = decrypted.decode(\"utf-8\") \n",
    "\n",
    "    # Append the decrypted data along with the columns to the list\n",
    "    decrypted_data.append((itemid, queueid, queuename, keyfield, keyvalue, status, attempt, tag, loaded, completed, exception, exceptionreason, deferred, finished, lastupdated, worktime, sessionid, priority, prevworktime, attemptworktime, exceptionreasonvarchar, exceptionreasontag, uniqueid, ident, decrypted))\n",
    "\n",
    "# Create a new dataframe to store the decrypted data and metadata\n",
    "filename_decrypted_df = pd.DataFrame(decrypted_data, columns=['itemid', 'queueid', 'queuename', 'keyfield', 'keyvalue', 'status', 'attempt', 'tag', 'loaded', 'completed', 'exception', 'exceptionreason', 'deferred', 'finished', 'lastupdated', 'worktime', 'sessionid', 'priority', 'prevworktime', 'attemptworktime', 'exceptionreasonvarchar', 'exceptionreasontag', 'uniqueid', 'ident', 'DecryptedData'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save decrypted files to Blob\n",
    "save_to_storage(filename_decrypted_df, container_name, filename_decrypted, folder_name_decrypted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
